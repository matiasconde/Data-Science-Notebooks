{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  NaN        NaN     5000.0       5000.0           4975.0   36 months   \n",
       "1  NaN        NaN     2500.0       2500.0           2500.0   60 months   \n",
       "2  NaN        NaN     2400.0       2400.0           2400.0   36 months   \n",
       "3  NaN        NaN    10000.0      10000.0          10000.0   36 months   \n",
       "4  NaN        NaN     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade       ...        \\\n",
       "0   10.65%       162.87     B        B2       ...         \n",
       "1   15.27%        59.83     C        C4       ...         \n",
       "2   15.96%        84.33     C        C5       ...         \n",
       "3   13.49%       339.31     C        C1       ...         \n",
       "4   12.69%        67.79     B        B5       ...         \n",
       "\n",
       "  hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "\n",
       "  disbursement_method  debt_settlement_flag debt_settlement_flag_date  \\\n",
       "0                Cash                     N                       NaN   \n",
       "1                Cash                     N                       NaN   \n",
       "2                Cash                     N                       NaN   \n",
       "3                Cash                     N                       NaN   \n",
       "4                Cash                     N                       NaN   \n",
       "\n",
       "  settlement_status settlement_date settlement_amount  settlement_percentage  \\\n",
       "0               NaN             NaN               NaN                    NaN   \n",
       "1               NaN             NaN               NaN                    NaN   \n",
       "2               NaN             NaN               NaN                    NaN   \n",
       "3               NaN             NaN               NaN                    NaN   \n",
       "4               NaN             NaN               NaN                    NaN   \n",
       "\n",
       "  settlement_term  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv('LoanStats3a.csv', skiprows=1,low_memory=False)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loans_2007 = loans_2007.drop(['desc', 'url'],axis=1)\n",
    "# half_count = len(loans_2007) / 2\n",
    "# loans_2007 = loans_2007.dropna(thresh=half_count, axis=1)\n",
    "# loans_2007.to_csv('loans_2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade    ...    last_pymnt_amnt  \\\n",
       "0   10.65%       162.87     B        B2    ...             171.62   \n",
       "1   15.27%        59.83     C        C4    ...             119.66   \n",
       "2   15.96%        84.33     C        C5    ...             649.91   \n",
       "3   13.49%       339.31     C        C1    ...             357.48   \n",
       "4   12.69%        67.79     B        B5    ...              67.79   \n",
       "\n",
       "  last_credit_pull_d collections_12_mths_ex_med  policy_code application_type  \\\n",
       "0           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "1           Sep-2013                        0.0          1.0       INDIVIDUAL   \n",
       "2           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "3           Apr-2016                        0.0          1.0       INDIVIDUAL   \n",
       "4           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "\n",
       "  acc_now_delinq chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies  \\\n",
       "0            0.0                      0.0         0.0                  0.0   \n",
       "1            0.0                      0.0         0.0                  0.0   \n",
       "2            0.0                      0.0         0.0                  0.0   \n",
       "3            0.0                      0.0         0.0                  0.0   \n",
       "4            0.0                      0.0         0.0                  0.0   \n",
       "\n",
       "  tax_liens  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv(\"loans_2007.csv\",low_memory=False)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST STEP: FEATURE PREPARATION\n",
    "#### Looking at the csv file\n",
    "\n",
    "The csv file contains 52 columns, we are going to examine in groups of 18.\n",
    "\n",
    "We are going to pay attention to any column that: \n",
    "\n",
    "- leak information from the future (after the loan has already been funded):\n",
    "This information comes from the credit evolution (comes from the future after that the loans is  funded; this information is never available for the investor.\n",
    "- don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club).\n",
    "- formatted poorly and need to be cleaned up.\n",
    "- require more data or a lot of processing to turn into a useful feature.\n",
    "- contain redundant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------------------------------------------------------------------------\n",
    "###### FIRST GROUP OF 18 COLUMNS: \n",
    "\n",
    "\n",
    "-    id: randomly generated field by Lending Club for unique identification purposes only\n",
    "-    member_id: also a randomly generated field by Lending Club for unique identification purposes only\n",
    "-    funded_amnt: leaks data from the future (after the loan is already started to be funded)\n",
    "-    funded_amnt_inv: also leaks data from the future (after the loan is already started to be funded)\n",
    "-    grade: contains redundant information as the interest rate column (int_rate)\n",
    "-    sub_grade: also contains redundant information as the interest rate column (int_rate)\n",
    "-    emp_title: requires other data and a lot of processing to potentially be useful\n",
    "-    issue_d: leaks data from the future (after the loan is already completed funded)\n",
    "++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\"id\",\"member_id\",\"funded_amnt\",\"funded_amnt_inv\",\"grade\",\"sub_grade\",\"emp_title\",\"issue_d\"]\n",
    "\n",
    "loans_2007.drop(labels=features_to_drop,inplace=True,axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SECOND GROUP OF 18 COLUMNS LIST: \n",
    "-    zip_code: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    "-    out_prncp: leaks data from the future, (after the loan already started to be paid off)\n",
    "-    out_prncp_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    "-    total_pymnt: also leaks data from the future, (after the loan already started to be paid off)\n",
    "-    total_pymnt_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    "-    total_rec_prncp: also leaks data from the future, (after the loan already started to be paid off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove2 = [\"zip_code\",\"out_prncp\",\"out_prncp_inv\",\"total_pymnt\",\"total_pymnt_inv\",\"total_rec_prncp\"]\n",
    "\n",
    "loans_2007.drop(labels=features_to_remove2,axis=\"columns\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### THIRD GROUP OF 18 COLUMNS LIST:\n",
    "-    total_rec_int: leaks data from the future, (after the loan already started to be paid off),\n",
    "-   total_rec_late_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    recoveries: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    collection_recovery_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    last_pymnt_d: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    last_pymnt_amnt: also leaks data from the future, (after the loan already started to be paid off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [loan_amnt, term, int_rate, installment, emp_length, home_ownership, annual_inc, verification_status, loan_status, pymnt_plan, purpose, title, addr_state, dti, delinq_2yrs, earliest_cr_line, inq_last_6mths, open_acc, pub_rec, revol_bal, revol_util, total_acc, initial_list_status, last_credit_pull_d, collections_12_mths_ex_med, policy_code, application_type, acc_now_delinq, chargeoff_within_12_mths, delinq_amnt, pub_rec_bankruptcies, tax_liens]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "features_to_drop3 = [\"total_rec_int\",\"total_rec_late_fee\",\"recoveries\",\"collection_recovery_fee\",\"last_pymnt_d\",\"last_pymnt_amnt\"]\n",
    "\n",
    "loans_2007.drop(labels=features_to_drop3,axis=\"columns\",inplace=True)\n",
    "\n",
    "print(loans_2007.head(0))\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECTING THE TARGET COLUMN: \n",
    "\n",
    "- Loan_status it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values and we need to convert it to a numerical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007[\"loan_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Meaning of the values: \n",
    "\n",
    "- Fully Paid:     Loan has been fully paid off.\n",
    "- Charged Off: \tLoan for which there is no longer a reasonable expectation of further payments.\n",
    "- Does not meet the credit policy: \tWhile the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "\n",
    "\n",
    "- Charged Off: While the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "\n",
    "\n",
    "- In Grace Period:\tThe loan is past due but still in the grace period of 15 days.\n",
    "- Late (16-30 days):\tLoan hasn't been paid in 16 to 30 days (late on the current payment). \n",
    "- Late (31-120 days):\tLoan hasn't been paid in 31 to 120 days (late on the current payment).\n",
    "- Current: \tLoan is up to date on current payments.\n",
    "- Default: \tLoan is defaulted on and no payment has been made for more than 121 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Only the Fully Paid and Charged Off values describe the final outcome of the loan. The other values describe loans that are still on going and where the jury is still out on if the borrower will pay back the loan on time or not. While the Default status resembles the Charged Off status, in Lending Club's eyes, loans that are charged off have essentially no chance of being repaid while default ones have a small chance. You can read about the difference here.\n",
    "\n",
    "Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. Let's remove all the loans that don't contain either Fully Paid and Charged Off as the loan's status and then transform the Fully Paid values to 1 for the positive case and the Charged Off values to 0 for the negative case.<i/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.loc[(loans_2007[\"loan_status\"]==\"Fully Paid\")|(loans_2007[\"loan_status\"]==\"Charged Off\")]\n",
    "\n",
    "mapping_dict = {\"loan_status\":{\"Fully Paid\":1,\"Charged Off\":0}}\n",
    "\n",
    "loans_2007.replace(to_replace=mapping_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look for any columns that contain only one unique value and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "drop_columns = []\n",
    "\n",
    "for column in loans_2007.columns:\n",
    "    serie = loans_2007[column]\n",
    "    serie.dropna(inplace=True)\n",
    "    uniques = serie.unique()\n",
    "    if len(uniques)<=1:\n",
    "        drop_columns.append(column)\n",
    "        \n",
    "loans_2007.drop(labels=drop_columns,axis=1,inplace=True)\n",
    "\n",
    "print(drop_columns)\n",
    "\n",
    "loans = loans_2007.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                  0\n",
      "term                       0\n",
      "int_rate                   0\n",
      "installment                0\n",
      "emp_length              1036\n",
      "home_ownership             0\n",
      "annual_inc                 0\n",
      "verification_status        0\n",
      "loan_status                0\n",
      "purpose                    0\n",
      "title                     11\n",
      "addr_state                 0\n",
      "dti                        0\n",
      "delinq_2yrs                0\n",
      "earliest_cr_line           0\n",
      "inq_last_6mths             0\n",
      "open_acc                   0\n",
      "pub_rec                    0\n",
      "revol_bal                  0\n",
      "revol_util                50\n",
      "total_acc                  0\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "null_counts = loans.isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### While most of the columns have 0 missing values, 2 columns have 50 or less rows with missing values, and 1 column, pub_rec_bankruptcies, contains 697 rows with missing values. Let's remove columns entirely where more than 1% of the rows for that column contain a null value. In addition, we'll remove the remaining rows containing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loans.drop(labels=[\"pub_rec_bankruptcies\"],inplace=True,axis=1)\n",
    "\n",
    "loans.dropna(how=\"any\",axis=0,inplace=True)\n",
    "\n",
    "print(loans.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The object columns that contain text need to be converted to numerical data types. Let's return a new Dataframe containing just the object columns so we can explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         term int_rate emp_length home_ownership verification_status  \\\n",
      "0   36 months   10.65%  10+ years           RENT            Verified   \n",
      "1   60 months   15.27%   < 1 year           RENT     Source Verified   \n",
      "\n",
      "       purpose     title addr_state earliest_cr_line revol_util  \\\n",
      "0  credit_card  Computer         AZ         Jan-1985      83.7%   \n",
      "1          car      bike         GA         Apr-1999       9.4%   \n",
      "\n",
      "  last_credit_pull_d  \n",
      "0           Jun-2016  \n",
      "1           Sep-2013  \n"
     ]
    }
   ],
   "source": [
    "object_columns_df = loans.select_dtypes(include=[object])\n",
    "\n",
    "print(object_columns_df[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some of the columns seem like they represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    "-    home_ownership: home ownership status, can only be 1 of 4 categorical values according to the data dictionary,\n",
    "-    verification_status: indicates if income was verified by Lending Club,\n",
    "-    emp_length: number of years the borrower was employed upon time of application,\n",
    "-    term: number of payments on the loan, either 36 or 60,\n",
    "-    addr_state: borrower's state of residence,\n",
    "-    purpose: a category provided by the borrower for the loan request,\n",
    "-    title: loan title provided the borrower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> <b>Based on the first row's values for purpose and title, it seems like these columns could reflect the same information.\n",
    "<i/></b>\n",
    "\n",
    "\n",
    "Some meanings:\n",
    "\n",
    "- int_rate: interest rate of the loan in %.\n",
    "- revol_util: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18112\n",
      "MORTGAGE    16686\n",
      "OWN          2778\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       16281\n",
      "Verified           11856\n",
      "Source Verified     9538\n",
      "Name: verification_status, dtype: int64\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1228\n",
      "Name: emp_length, dtype: int64\n",
      " 36 months    28234\n",
      " 60 months     9441\n",
      "Name: term, dtype: int64\n",
      "CA    6776\n",
      "NY    3614\n",
      "FL    2704\n",
      "TX    2613\n",
      "NJ    1776\n",
      "IL    1447\n",
      "PA    1442\n",
      "VA    1347\n",
      "GA    1323\n",
      "MA    1272\n",
      "OH    1149\n",
      "MD    1008\n",
      "AZ     807\n",
      "WA     788\n",
      "CO     748\n",
      "NC     729\n",
      "CT     711\n",
      "MI     678\n",
      "MO     648\n",
      "MN     581\n",
      "NV     466\n",
      "SC     454\n",
      "WI     427\n",
      "OR     422\n",
      "AL     420\n",
      "LA     420\n",
      "KY     311\n",
      "OK     285\n",
      "KS     249\n",
      "UT     249\n",
      "AR     229\n",
      "DC     209\n",
      "RI     194\n",
      "NM     180\n",
      "WV     164\n",
      "HI     162\n",
      "NH     157\n",
      "DE     110\n",
      "MT      77\n",
      "WY      76\n",
      "AK      76\n",
      "SD      60\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "IA       5\n",
      "NE       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for c in cols:\n",
    "    print(loans[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The home_ownership, verification_status, emp_length, term, and addr_state columns all contain multiple discrete values. We should clean the emp_length column and treat it as a numerical one since the values have ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_consolidation    17751\n",
      "credit_card            4911\n",
      "other                  3711\n",
      "home_improvement       2808\n",
      "major_purchase         2083\n",
      "small_business         1719\n",
      "car                    1459\n",
      "wedding                 916\n",
      "medical                 655\n",
      "moving                  552\n",
      "house                   356\n",
      "vacation                348\n",
      "educational             312\n",
      "renewable_energy         94\n",
      "Name: purpose, dtype: int64\n",
      "Debt Consolidation           2068\n",
      "Debt Consolidation Loan      1599\n",
      "Personal Loan                 624\n",
      "Consolidation                 488\n",
      "debt consolidation            466\n",
      "Credit Card Consolidation     345\n",
      "Home Improvement              336\n",
      "Debt consolidation            314\n",
      "Small Business Loan           298\n",
      "Credit Card Loan              294\n",
      "Personal                      290\n",
      "Consolidation Loan            250\n",
      "Home Improvement Loan         228\n",
      "personal loan                 219\n",
      "Loan                          202\n",
      "Wedding Loan                  199\n",
      "personal                      198\n",
      "Car Loan                      188\n",
      "consolidation                 186\n",
      "Other Loan                    168\n",
      "Wedding                       148\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Purpose and title looking the best column to use: \n",
    "print(loans[\"purpose\"].value_counts())\n",
    "print(loans[\"title\"].value_counts().head(21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It seems like the purpose and title columns do contain overlapping information but we'll keep the purpose column since it contains a few discrete values. In addition, the title column has data quality issues since many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation)\n",
    "\n",
    "\n",
    "The home_ownership, verification_status, emp_length, and term columns each contain a few discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "\n",
    "We erred on the side of being conservative with the 10+ years, < 1 year and n/a mappings. We assume that people who may have been working more than 10 years have only really worked for 10 years. We also assume that people who've worked less than a year or if the information is not available that they've worked for 0. This is a general heuristic but it's not perfect.\n",
    "\n",
    "The addr_state column contains many discrete values and we'd need to add 49 dummy variable columns to use it for classification. This would make our Dataframe much larger and could slow down how quickly the code runs. Let's remove this column from consideration.\n",
    "\n",
    "Lastly, some of the columns contain date values that would require a good amount of feature engineering for them to be potentially useful:\n",
    "\n",
    "    earliest_cr_line: The month the borrower's earliest reported credit line was opened,\n",
    "    last_credit_pull_d: The most recent month Lending Club pulled credit for this loan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the following mapping to clean the emp_length column:\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans.drop(labels=[\"last_credit_pull_d\",\"addr_state\",\"title\",\"earliest_cr_line\"],axis=1,inplace=True)\n",
    "\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(float)\n",
    "\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(float)\n",
    "\n",
    "loans.replace(to_replace=mapping_dict,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now encode the home_ownership, verification_status, purpose, and term columns as dummy \n",
    "#variables so we can use them in our model. We first need to use the Pandas get_dummies.\n",
    "df_dummies = pd.get_dummies(loans[[\"home_ownership\",\"verification_status\",\"purpose\",\"term\"]])\n",
    "\n",
    "loans.drop(labels=[\"home_ownership\",\"verification_status\",\"purpose\",\"term\"],axis=1,inplace=True)\n",
    "\n",
    "loans = pd.concat([loans,df_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we prepared the data, we removed columns that had data leakage issues, contained \n",
    "#redundant information, or required additional processing to turn into useful features. \n",
    "# We cleaned features that had formatting issues, and converted categorical columns to dummy variables.\n",
    "\n",
    "loans.to_csv(\"cleaned_loans_2007.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL STEP: TESTING MODELS\n",
    "\n",
    "##### Objective: build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not. standpoint of a conservative investor.\n",
    "\n",
    "- Rmemember: there's a class imbalance in our target column, loan_status. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models.\n",
    "This causes a major issue when we use accuracy as a metric. This is because due to the class imbalance, a classifier can predict 1 for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37675 entries, 0 to 37674\n",
      "Data columns (total 39 columns):\n",
      "Unnamed: 0                             37675 non-null int64\n",
      "loan_amnt                              37675 non-null float64\n",
      "int_rate                               37675 non-null float64\n",
      "installment                            37675 non-null float64\n",
      "emp_length                             37675 non-null int64\n",
      "annual_inc                             37675 non-null float64\n",
      "loan_status                            37675 non-null int64\n",
      "dti                                    37675 non-null float64\n",
      "delinq_2yrs                            37675 non-null float64\n",
      "inq_last_6mths                         37675 non-null float64\n",
      "open_acc                               37675 non-null float64\n",
      "pub_rec                                37675 non-null float64\n",
      "revol_bal                              37675 non-null float64\n",
      "revol_util                             37675 non-null float64\n",
      "total_acc                              37675 non-null float64\n",
      "home_ownership_MORTGAGE                37675 non-null int64\n",
      "home_ownership_NONE                    37675 non-null int64\n",
      "home_ownership_OTHER                   37675 non-null int64\n",
      "home_ownership_OWN                     37675 non-null int64\n",
      "home_ownership_RENT                    37675 non-null int64\n",
      "verification_status_Not Verified       37675 non-null int64\n",
      "verification_status_Source Verified    37675 non-null int64\n",
      "verification_status_Verified           37675 non-null int64\n",
      "purpose_car                            37675 non-null int64\n",
      "purpose_credit_card                    37675 non-null int64\n",
      "purpose_debt_consolidation             37675 non-null int64\n",
      "purpose_educational                    37675 non-null int64\n",
      "purpose_home_improvement               37675 non-null int64\n",
      "purpose_house                          37675 non-null int64\n",
      "purpose_major_purchase                 37675 non-null int64\n",
      "purpose_medical                        37675 non-null int64\n",
      "purpose_moving                         37675 non-null int64\n",
      "purpose_other                          37675 non-null int64\n",
      "purpose_renewable_energy               37675 non-null int64\n",
      "purpose_small_business                 37675 non-null int64\n",
      "purpose_vacation                       37675 non-null int64\n",
      "purpose_wedding                        37675 non-null int64\n",
      "term_ 36 months                        37675 non-null int64\n",
      "term_ 60 months                        37675 non-null int64\n",
      "dtypes: float64(12), int64(27)\n",
      "memory usage: 11.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv(\"cleaned_loans_2007.csv\")\n",
    "\n",
    "print(loans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNTING TYPE OF ERROS (REMEMBER): \n",
    "\n",
    "tn = ((predictions==0)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "tp = ((predictions==1)&(loans[\"loan_status\"]==1)).sum()\n",
    "\n",
    "fp = ((predictions==1)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "fn = ((predictions==0)&(loans[\"loan_status\"]==1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We established that this is a binary classification problem\n",
    "\n",
    "#### Error Metrics :\n",
    "In this case, we're primarily concerned with false positives and false negatives. In the first one we are go to loose money, in the second one we loose the possibilitie of win money. The true positivies and true negatives are the coorect predictions and don't contribute to the error metric. \n",
    "\n",
    "<I> conservative investor would want to minimize risk, and avoid false positives as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should optimize for:\n",
    "\n",
    "-   high recall (true positive rate) --> tpr = tp / (tp + fn)\n",
    "-   low fall-out (false positive rate) --> fpr = fp / (fp + tn)-\n",
    "\n",
    "\n",
    "-    False Positive Rate -- \"what percentage of my 1 predictions are incorrect?\"\n",
    " -       In this case, \"what percentage of the loans that I fund would not be repaid?\"\n",
    "-  True Positive Rate -- \"what percentage of all the possible 1 predictions am I making?\"\n",
    "   -     In this case, \"what percentage of loans that could be funded would I fund?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#Supose that we predict all ones: \n",
    "#Predict that all loans will be paid off on time.\n",
    "predictions = pd.Series(np.ones(loans.shape[0]))\n",
    "\n",
    "tn = ((predictions==0)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "tp = ((predictions==1)&(loans[\"loan_status\"]==1)).sum()\n",
    "\n",
    "fp = ((predictions==1)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "fn = ((predictions==0)&(loans[\"loan_status\"]==1)).sum()\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>both metrics are 1: all rows to one, we predict correctly all tp but fn = 0 (because there is no predictions-value 0!\n",
    "also there is no predictions value for tnSames with fp because there is not 0's!) then both ratios are fp/fp and tp/tp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Logistics regressions because: \n",
    "\n",
    "  -   it's quick to train and we can iterate more quickly,\n",
    "  -  it's less prone to overfitting than more complex models like decision trees,\n",
    "  - it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = loans.drop(\"loan_status\",axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features,target)\n",
    "predictions = lr.predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614028576730377 0.9878894877036486\n"
     ]
    }
   ],
   "source": [
    "# In order to get a realistic depiction of the accuracy of the model, let's perform k-fold cross validation. \n",
    "# We can use the cross_val_predict() function from the sklearn.model_selection package\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "predictions = cross_val_predict(lr,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Theory:\n",
    "\n",
    "We'll look into oversampling and undersampling first. They involve taking a sample that contains equal numbers of rows where loan_status is 0, and where loan_status is 1. This way, the classifier is forced to make actual predictions, since predicting all 1s or all 0s will only result in 50% accuracy at most.\n",
    "\n",
    "The downside of this technique is that since it has to preserve an equal ratio, you have to either:\n",
    "\n",
    "    - Throw out many rows of data. If we wanted equal numbers of rows where loan_status is 0 and where loan_status is 1, one way we could do that is to delete rows where loan_status is 1.\n",
    "    - Copy rows multiple times. One way to equalize the 0s and 1s is to copy rows where loan_status is 0.\n",
    "    - Generate fake data. One way to equalize the 0s and 1s is to generate new rows where loan_status is 0.\n",
    "    \n",
    "Unfortunately, none of these techniques are especially easy. The second method we mentioned earlier, telling the classifier to penalize certain rows more, is actually much easier to implement using scikit-learn.\n",
    "\n",
    "We can do this by setting the class_weight parameter to balanced when creating the LogisticRegression instance. This tells scikit-learn to penalize the misclassification of the minority class during the training process. The penalty means that the logistic regression classifier pays more attention to correctly classifying rows where loan_status is 0. This lowers accuracy when loan_status is 1, but raises accuracy when loan_status is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "###### By setting the class_weight parameter to balanced, the penalty is set to be inversely proportional to the class frequencies. You can read more about the parameter here. This would mean that for the classifier, correctly classifying a row where loan_status is 0 is 6 times more important than correctly classifying a row where loan_status is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3978474670625348 0.6181936443040327\n"
     ]
    }
   ],
   "source": [
    "#Again with data-set balanced\n",
    "\n",
    "lr = LogisticRegression(class_weight = \"balanced\")\n",
    "\n",
    "predictions = cross_val_predict(lr,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We significantly improved false positive rate in the last screen by balancing the classes, which reduced true positive rate. Our true positive rate is now around 62%, and our false positive rate is around 40%.\n",
    "###### We want to reduce more the fpr, then we can assign manually the penalties: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2408610131749861 0.3630366102954841\n"
     ]
    }
   ],
   "source": [
    "#Again with manual penalties:\n",
    "\n",
    "penalty = {0:10,1:1}\n",
    "\n",
    "lr = LogisticRegression(class_weight = penalty)\n",
    "\n",
    "predictions = cross_val_predict(lr,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It looks like assigning manual penalties lowered the false positive rate to 24%, and thus lowered our risk. Note that this comes at the expense of true positive rate. While we have fewer false positives, we're also missing opportunities to fund more loans and potentially make more money. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "### TRYING ANOTHER MODEL:\n",
    "###### Random forests are able to work with nonlinear data, and learn complex conditionals. Logistic regressions are only able to work with linear data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6359250324735573 0.6550826983832001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1,class_weight=\"balanced\")\n",
    "\n",
    "predictions = cross_val_predict(rf,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSIONS:\n",
    "<i><r>\n",
    "Unfortunately, using a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the 1 class, and still mostly predicting 1s. We could fix this by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of 24%, and a true positive rate of 36%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 24% of borrowers defaulting, and that the pool of 36% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would. Given this, there's still quite a bit of room to improve:\n",
    "\n",
    "    We can tweak the penalties further.\n",
    "    We can try models other than a random forest and logistic regression.\n",
    "    We can use some of the columns we discarded to generate better features.\n",
    "    We can ensemble multiple models to get more accurate predictions.\n",
    "    We can tune the parameters of the algorithm to achieve higher performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
